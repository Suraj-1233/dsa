# ğŸŒŸ Sorting Algorithms Detailed Summary

## âœ… 1ï¸âƒ£ Bubble Sort

### ğŸ’¡ Working

Repeatedly compare adjacent elements and swap if they are in the wrong order. After each pass, the largest element "bubbles" to the end.

### âš¡ Time Complexity

* Best: O(n)
* Average: O(nÂ²)
* Worst: O(nÂ²)

### ğŸ—‚ï¸ Space Complexity

* O(1)

### âœ… Advantages

* Simple to understand
* Detects if already sorted

### âŒ Disadvantages

* Very slow on large datasets

### ğŸ’¬ When to use?

* Small or nearly sorted arrays

---

## âœ… 2ï¸âƒ£ Selection Sort

### ğŸ’¡ Working

Find the minimum element and put it in its correct position in each iteration.

### âš¡ Time Complexity

* Best: O(nÂ²)
* Average: O(nÂ²)
* Worst: O(nÂ²)

### ğŸ—‚ï¸ Space Complexity

* O(1)

### âœ… Advantages

* Minimum number of swaps

### âŒ Disadvantages

* Always O(nÂ²), even if already sorted

### ğŸ’¬ When to use?

* When memory writes are costly

---

## âœ… 3ï¸âƒ£ Insertion Sort

### ğŸ’¡ Working

Start from the second element and insert each element into its correct position in the sorted left part.

### âš¡ Time Complexity

* Best: O(n)
* Average: O(nÂ²)
* Worst: O(nÂ²)

### ğŸ—‚ï¸ Space Complexity

* O(1)

### âœ… Advantages

* Simple and efficient for small or nearly sorted arrays
* Stable

### âŒ Disadvantages

* Inefficient on large datasets

### ğŸ’¬ When to use?

* Small datasets or almost sorted arrays

---

## âœ… 4ï¸âƒ£ Merge Sort

### ğŸ’¡ Working

Divide the array into halves recursively, then merge the sorted halves.

### âš¡ Time Complexity

* Best: O(n log n)
* Average: O(n log n)
* Worst: O(n log n)

### ğŸ—‚ï¸ Space Complexity

* O(n)

### âœ… Advantages

* Guaranteed O(n log n)
* Stable

### âŒ Disadvantages

* Uses extra space

### ğŸ’¬ When to use?

* When stability is required and performance guarantee is important

---

## âœ… 5ï¸âƒ£ Quick Sort

### ğŸ’¡ Working

Pick a pivot, partition elements into smaller and greater than pivot, and recursively sort partitions.

### âš¡ Time Complexity

* Best: O(n log n)
* Average: O(n log n)
* Worst: O(nÂ²)

### ğŸ—‚ï¸ Space Complexity

* O(log n)

### âœ… Advantages

* Fast on average
* In-place

### âŒ Disadvantages

* Not stable
* Worst-case O(nÂ²)

### ğŸ’¬ When to use?

* Large datasets when average performance is more important than worst case

---

## âœ… 6ï¸âƒ£ Heap Sort

### ğŸ’¡ Working

Build a max heap, repeatedly remove the root (max), place at the end.

### âš¡ Time Complexity

* Best: O(n log n)
* Average: O(n log n)
* Worst: O(n log n)

### ğŸ—‚ï¸ Space Complexity

* O(1)

### âœ… Advantages

* In-place
* No extra memory needed

### âŒ Disadvantages

* Not stable
* Often slower in practice compared to Quick Sort

### ğŸ’¬ When to use?

* When constant extra space is required, and stability isnâ€™t needed

---

# ğŸ¯ Quick Summary Table

| Algorithm      | Best       | Average    | Worst      | Space    | Stable | When to Use                    |
| -------------- | ---------- | ---------- | ---------- | -------- | ------ | ------------------------------ |
| Bubble Sort    | O(n)       | O(nÂ²)      | O(nÂ²)      | O(1)     | âœ… Yes  | Very small or nearly sorted    |
| Selection Sort | O(nÂ²)      | O(nÂ²)      | O(nÂ²)      | O(1)     | âŒ No   | When minimum swaps needed      |
| Insertion Sort | O(n)       | O(nÂ²)      | O(nÂ²)      | O(1)     | âœ… Yes  | Small or nearly sorted arrays  |
| Merge Sort     | O(n log n) | O(n log n) | O(n log n) | O(n)     | âœ… Yes  | Stability & guaranteed perf.   |
| Quick Sort     | O(n log n) | O(n log n) | O(nÂ²)      | O(log n) | âŒ No   | Large datasets, fast avg perf. |
| Heap Sort      | O(n log n) | O(n log n) | O(n log n) | O(1)     | âŒ No   | When minimal space needed      |

---

## âœ… Easy Reminder Tips

* **Bubble:** Big bubbles go to the end.
* **Selection:** Select the smallest repeatedly.
* **Insertion:** Insert into sorted left part.
* **Merge:** Divide and merge.
* **Quick:** Pivot and partition.
* **Heap:** Heapify and remove root.

---

ğŸ *Feel free to copy this into your README.md directly!*
